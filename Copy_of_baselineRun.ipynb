{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPkM2H5VLFA4LZVOkTqkWhy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/md131376st/amlProj/blob/main/Copy_of_baselineRun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFcYJh0-Om-l",
        "outputId": "ea52cb61-cd04-4609-8990-75a9a6c3b5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'amlProj'...\n",
            "remote: Enumerating objects: 10120, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 10120 (delta 32), reused 77 (delta 29), pack-reused 10035\u001b[K\n",
            "Receiving objects: 100% (10120/10120), 174.18 MiB | 55.44 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "Checking out files: 100% (10005/10005), done.\n",
            "/content/amlProj\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting git+https://github.com/openai/CLIP.git (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-vt3kv1u8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-vt3kv1u8\n",
            "  Resolved https://github.com/openai/CLIP.git to commit d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==1.10.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1821.4 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1821417472 bytes == 0x22b4000 @  0x7f584ca9b1e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m174.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2276777984 bytes == 0x6ebbe000 @  0x7f584ca9c615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941\n",
            "tcmalloc: large alloc 1821417472 bytes == 0x22b4000 @  0x7f584ca9b1e7 0x4d30a0 0x5dede2 0x6758aa 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4fe318 0x5da092 0x62042c 0x5d8d8c 0x561f80 0x4fd2db 0x4997c7 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.11.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.11.0%2Bcu113-cp38-cp38-linux_x86_64.whl (21.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.1.1\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex==2022.9.13\n",
            "  Downloading regex-2022.9.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.0+cu113->-r requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.0+cu113->-r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.0+cu113->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 4)) (0.2.5)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369408 sha256=49fd414bf35e227c8eab1fb886f20f59f6c2b5fc0cf058154702332aeed54b39\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b9s10dma/wheels/ab/4f/3a/5e51521b55997aa6f0690e095c08824219753128ce8d9969a3\n",
            "Successfully built clip\n",
            "Installing collected packages: torch, regex, ftfy, torchvision, clip\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.6.2\n",
            "    Uninstalling regex-2022.6.2:\n",
            "      Successfully uninstalled regex-2022.6.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.10.0+cu113 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.10.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed clip-1.0 ftfy-6.1.1 regex-2022.9.13 torch-1.10.0+cu113 torchvision-0.11.0+cu113\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.isdir('amlProj'):\n",
        "  !git clone https://github.com/md131376st/amlProj.git\n",
        "  %cd amlProj\n",
        "  !pip install -r 'requirements.txt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --experiment baseline --target_domain cartoon\n"
      ],
      "metadata": {
        "id": "jF8b_NhyPBiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f02b73-096c-464d-e8b9-f5df7d9c15c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 199MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --experiment baseline --target_domain sketch"
      ],
      "metadata": {
        "id": "3BarNJsCZ6mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --experiment baseline --target_domain photo"
      ],
      "metadata": {
        "id": "o-ircDtZARX1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}